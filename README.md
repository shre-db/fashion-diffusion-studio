# ğŸ‘— Fashion Diffusion Studio

**AI-powered toolkit for generating and editing fashion images using state-of-the-art diffusion models.**

Fashion Diffusion Studio enables product designers, marketers, and developers to create and modify high-quality fashion visuals using text prompts, pose control, and inpainting. Built on top of Stable Diffusion, LoRA fine-tuning, and ControlNet, it allows for rapid prototyping of lookbooks, product mockups, and ad creativesâ€”all without a traditional photoshoot.

---

## âœ¨ Features

- ğŸ¨ **Text-to-Fashion Image Generation**  
  Generate outfits, models, and accessories using natural language prompts.

- ğŸ§ **Pose-Controlled Generation**  
  Use ControlNet to generate consistent human poses or clone campaign shots.

- âœ‚ï¸ **Garment Inpainting**  
  Edit specific clothing items in a photo while preserving the original model.

- ğŸ§  **LoRA Fine-Tuning Pipeline**  
  Fine-tune lightweight diffusion adapters on your own fashion brand/style.

- ğŸ–¥ï¸ **Streamlit Web App**  
  Try it out in an interactive UI for real-time generation and editing.

---

## ğŸ–¼ï¸ Example Outputs

<!-- You can later replace these with real examples -->
| Prompt | Output |
|--------|--------|
| `a model wearing a red trench coat on a runway` | ![example1](app/assets/example1.jpg) |
| `change shirt to leather jacket` (inpainting) | ![example2](app/assets/example2.jpg) |

---

## ğŸ§± Folder Structure

```plaintext
fashion-diffusion-studio/
â”œâ”€â”€ models/                         # Core model components
â”‚   â”œâ”€â”€ base/                       # Base SD models (v1.5, inpainting, ControlNet)
â”‚   â”œâ”€â”€ lora/                       # Fine-tuned LoRA weights/checkpoints
â”‚   â”œâ”€â”€ dreambooth/                # DreamBooth weights, config
â”‚   â””â”€â”€ utils.py                   # Helper functions for model loading/running

â”œâ”€â”€ data/                          # Dataset-related files
â”‚   â”œâ”€â”€ raw/                       # Raw image and caption data
â”‚   â”œâ”€â”€ processed/                 # Preprocessed datasets (resized, masked, tagged)
â”‚   â”œâ”€â”€ annotations/              # Captions, pose maps, segmentation masks
â”‚   â””â”€â”€ metadata.json             # JSON to track versions, sources

â”œâ”€â”€ training/                      # Training scripts and configs
â”‚   â”œâ”€â”€ lora_train.py              # LoRA fine-tuning script
â”‚   â”œâ”€â”€ dreambooth_train.py        # DreamBooth fine-tuning
â”‚   â”œâ”€â”€ preprocess.py              # Image resizing, tagging, captioning
â”‚   â””â”€â”€ configs/                   # YAML configs for experiments

â”œâ”€â”€ editing/                       # Image editing and inpainting logic
â”‚   â”œâ”€â”€ inpaint.py                 # Garment editing via inpainting
â”‚   â”œâ”€â”€ controlnet_edit.py        # Editing with ControlNet (pose, edge)
â”‚   â””â”€â”€ segmenter.py              # Garment segmentation or mask generator

â”œâ”€â”€ generation/                    # Image generation pipeline
â”‚   â”œâ”€â”€ text2img.py                # Prompt-based generation
â”‚   â”œâ”€â”€ pose_guided_gen.py        # Generate images with pose control
â”‚   â””â”€â”€ prompt_templates.py       # Modular prompt templates for fashion items

â”œâ”€â”€ app/                           # Web UI and demo app (Gradio or Streamlit)
â”‚   â”œâ”€â”€ gradio_app.py              # Main app file
â”‚   â”œâ”€â”€ assets/                    # Icons, default images
â”‚   â””â”€â”€ templates/                 # UI layout templates

â”œâ”€â”€ backend/                       # Optional API backend (FastAPI)
â”‚   â”œâ”€â”€ api.py                     # Inference endpoints
â”‚   â””â”€â”€ models.py                  # Pydantic schemas

â”œâ”€â”€ infra/                         # Deployment & environment setup
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ install.sh                 # Dependency install script
â”‚   â””â”€â”€ e2e_launcher.py            # Launch automation (E2E Networks compatible)

â”œâ”€â”€ notebooks/                     # Research, experimentation, and demos
â”‚   â”œâ”€â”€ 01_lora_training.ipynb
â”‚   â”œâ”€â”€ 02_inpainting_demo.ipynb
â”‚   â””â”€â”€ 03_prompt_experiments.ipynb

â”œâ”€â”€ scripts/                       # Utility scripts (scraping, cleaning, etc.)
â”‚   â”œâ”€â”€ scrape_dataset.py          # For collecting fashion images
â”‚   â””â”€â”€ generate_poses.py          # OpenPose or PoseNet extraction

â”œâ”€â”€ tests/                         # Unit and integration tests
â”‚   â”œâ”€â”€ test_generation.py
â”‚   â””â”€â”€ test_editing.py

â”œâ”€â”€ configs/                       # Global config files
â”‚   â””â”€â”€ project_config.yaml

â”œâ”€â”€ .env.example                   # Template for env vars (e.g., HF_TOKEN, API keys)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                      # Project overview, instructions
â”œâ”€â”€ requirements.txt               # Pip dependencies
â””â”€â”€ environment.yml                # Conda environment file
```


## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/fashion-diffusion-studio.git
cd fashion-diffusion-studio
```

### 2. Set Up Environment
With Conda
```bash
conda env create -f environment.yml
conda activate fashion-diffusion
```

Or with pip
```bash
pip install -r requirements.txt
```

### 3. Run the App
```bash
streamlit run app/streamlit_app.py
```

## âš™ï¸ Fine-Tuning (LoRA)
1. Prepare your dataset in `data/processed/`
2. Configure training in training/configs/lora_config.yaml
3. Run:
```bash 
python training/lora_train.py --config training/configs/lora_config.yaml
```

## ğŸ“¦ Pretrained Models
| Model Type              | Source                                    |
| ----------------------- | ----------------------------------------- |
| Stable Diffusion 1.5    | `runwayml/stable-diffusion-v1-5`          |
| Inpainting              | `stabilityai/stable-diffusion-inpainting` |
| ControlNet (pose/canny) | `lllyasviel/ControlNet`                   |
| LoRA                    | Saved in `models/lora/` after training    |


## ğŸ§ª Evaluation

- CLIP similarity scoring
- Attribute match (planned)
- Visual A/B comparison UI (coming soon)

## ğŸ“¸ Use Cases

- Virtual try-on and style previews
- Social media asset generation
- Fashion product prototyping
- Brand lookbook automation

## ğŸ›¡ï¸ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contributors
- Shreyas - Project Lead

## ğŸ“¬ Contact
Questions or collaborations?\
ğŸ“§ Email: shreyasdb99@gmail.com\
ğŸŒ GitHub: shryzium
